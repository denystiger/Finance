{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:05.642721Z",
     "start_time": "2025-06-14T10:43:29.771273Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from sympy.physics.units.systems.mksa import units\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load and scale data\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "X_main, X_test, y_main, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_main, y_main, test_size=0.2, random_state=42)\n",
    "\n",
    "# Custom Huber loss function\n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1.0\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "# Build the model\n",
    "model = keras.models.Sequential([\n",
    "    layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    layers.Dense(30, activation=\"relu\"),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=huber_fn, optimizer=\"nadam\")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 12:43:40.169921: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/Documents/MYSpace/FinPy/.venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 0.5312 - val_loss: 0.2153\n",
      "Epoch 2/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1883 - val_loss: 0.1888\n",
      "Epoch 3/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1707 - val_loss: 0.1755\n",
      "Epoch 4/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1644 - val_loss: 0.1656\n",
      "Epoch 5/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1506 - val_loss: 0.1641\n",
      "Epoch 6/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1552 - val_loss: 0.1607\n",
      "Epoch 7/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1488 - val_loss: 0.1561\n",
      "Epoch 8/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1427 - val_loss: 0.1531\n",
      "Epoch 9/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1387 - val_loss: 0.1564\n",
      "Epoch 10/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1355 - val_loss: 0.1524\n",
      "Epoch 11/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1335 - val_loss: 0.1480\n",
      "Epoch 12/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1418 - val_loss: 0.1502\n",
      "Epoch 13/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1389 - val_loss: 0.1438\n",
      "Epoch 14/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1370 - val_loss: 0.1443\n",
      "Epoch 15/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 0.1266 - val_loss: 0.1438\n",
      "Epoch 16/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1288 - val_loss: 0.1426\n",
      "Epoch 17/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1343 - val_loss: 0.1436\n",
      "Epoch 18/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1280 - val_loss: 0.1428\n",
      "Epoch 19/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1287 - val_loss: 0.1407\n",
      "Epoch 20/20\n",
      "\u001B[1m413/413\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.1269 - val_loss: 0.1388\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:05.678597Z",
     "start_time": "2025-06-14T10:44:05.673131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(1.0 + tf.exp(z))\n",
    "def my_initializer(shape, dtype = tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev = stddev, dtype = dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "def my_positive_weights(weights):\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)\n",
    "\n",
    "layer = tf.keras.layers.Dense(1, activation = my_softplus,\n",
    "                              kernel_initializer=my_initializer,\n",
    "                              kernel_regularizer=my_l1_regularizer,\n",
    "                              kernel_constraint=my_positive_weights)"
   ],
   "id": "8413f78d0efaf8be",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:05.709707Z",
     "start_time": "2025-06-14T10:44:05.706011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyL1Regularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return{\"factor\": self.factor}"
   ],
   "id": "d4ce6bcb5366b56e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:05.732454Z",
     "start_time": "2025-06-14T10:44:05.730431Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "21efedc491d9872a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:05.789461Z",
     "start_time": "2025-06-14T10:44:05.752853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "precision = tf.keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])\n",
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])\n",
    "\n"
   ],
   "id": "1424abab39309547",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:05.818210Z",
     "start_time": "2025-06-14T10:44:05.813115Z"
    }
   },
   "cell_type": "code",
   "source": "precision.result()",
   "id": "a64b2529e2a064e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:05.847592Z",
     "start_time": "2025-06-14T10:44:05.842598Z"
    }
   },
   "cell_type": "code",
   "source": "precision.variables",
   "id": "8a99357dd3e16a07",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Variable path=precision/true_positives, shape=(1,), dtype=float32, value=[4.]>,\n",
       " <Variable path=precision/false_positives, shape=(1,), dtype=float32, value=[4.]>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:05.884608Z",
     "start_time": "2025-06-14T10:44:05.880857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = threshold * tf.abs(error) - threshold ** 2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ],
   "id": "7936f908d71135fc",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:05.910870Z",
     "start_time": "2025-06-14T10:44:05.905708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HuberMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, threshold = 1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer = 'zeros')\n",
    "        self.count = self.add_weight('count', initializer = 'zeros')\n",
    "    def update_state(self, y_true, y_pred, sample_weight = None):\n",
    "        sample_metrics = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(sample_metrics))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}\n",
    "    "
   ],
   "id": "2b8db2c9d68de63f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:05.932932Z",
     "start_time": "2025-06-14T10:44:05.930939Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ea4251d9b96536a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:05.956706Z",
     "start_time": "2025-06-14T10:44:05.952771Z"
    }
   },
   "cell_type": "code",
   "source": "tf.keras.layers.Flatten",
   "id": "25b005ee08bb0907",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.src.layers.reshaping.flatten.Flatten"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:05.983806Z",
     "start_time": "2025-06-14T10:44:05.980089Z"
    }
   },
   "cell_type": "code",
   "source": "exponential_layer = tf.keras.layers.Lambda(lambda x: tf.exp(x))",
   "id": "7e638bd553ee7a2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:06.008915Z",
     "start_time": "2025-06-14T10:44:06.004193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation = None, **kwargs):\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name = 'kernel', shape = [batch_input_shape[-1], self.units],\n",
    "            initializer = \"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name = \"bias\", shape = [self.units], initializer = 'zeros')\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": tf.keras.activations.serialize(self.activation)}"
   ],
   "id": "2a60eae6bf93241",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:06.031493Z",
     "start_time": "2025-06-14T10:44:06.028053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyMultiLayer(tf.keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        return X1 + X2, X1 * X2, X1 / X2"
   ],
   "id": "6f4879da2764399e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:13.645050Z",
     "start_time": "2025-06-14T10:44:13.641351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyGaussianNoise(tf.keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev"
   ],
   "id": "ba95b521e4238291",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:44:14.385964Z",
     "start_time": "2025-06-14T10:44:14.381985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyGaussianNoise(tf.keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        super().init(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training =  False):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev = self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X"
   ],
   "id": "6ca14c333312b341",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:45:54.723430Z",
     "start_time": "2025-06-14T10:45:54.717490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = [tf.keras.layers.Dense(n_neurons, activation = 'relu',\n",
    "                                             kernel_initializer='he_normal')]\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z\n",
    "\n",
    "class ResidualRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = tf.keras.layers.Dense(30, activation = \"relu\",\n",
    "                                                 kernel_initializer='he_normal')\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = tf.keras.layers.Dense(output_dim)\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ],
   "id": "218b1ac570fca7e9",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:53:26.520044Z",
     "start_time": "2025-06-14T10:53:26.513889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReconstructingRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [tf.keras.layers.Dense(30, activation = 'relu',\n",
    "                       kernel_initializer = 'he_normal') for _ in range(5)]\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = tf.keras.layers.Dense(n_inputs)\n",
    "\n",
    "\n",
    "    def call(self, inputs, training = False):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        if training:\n",
    "            result = self.reconstruction_mean(recon_loss)\n",
    "            self.add_metric(result)\n",
    "        return self.out(Z)"
   ],
   "id": "6519212d892fe4d9",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:56:04.998486Z",
     "start_time": "2025-06-14T10:56:04.995047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 **2 + 2 * w1 * w2"
   ],
   "id": "506f178a1cbdc1e0",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:56:25.949636Z",
     "start_time": "2025-06-14T10:56:25.944125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps\n",
    "\n",
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ],
   "id": "5d23011beb0813b2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T11:00:40.968463Z",
     "start_time": "2025-06-14T11:00:40.928044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "gradients = tape.gradient(z, [w1, w2])\n",
    "gradients\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2)\n",
    "del tape"
   ],
   "id": "b5fff6df1956dcfd",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m     z \u001B[38;5;241m=\u001B[39m f(w1, w2)\n\u001B[1;32m      8\u001B[0m dz_dw1 \u001B[38;5;241m=\u001B[39m tape\u001B[38;5;241m.\u001B[39mgradient(z, w1)\n\u001B[0;32m----> 9\u001B[0m dz_dw2 \u001B[38;5;241m=\u001B[39m \u001B[43mtape\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradient\u001B[49m\u001B[43m(\u001B[49m\u001B[43mz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m tape\n",
      "File \u001B[0;32m~/Documents/MYSpace/FinPy/.venv/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:1005\u001B[0m, in \u001B[0;36mGradientTape.gradient\u001B[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[1;32m    965\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Computes the gradient using operations recorded in context of this tape.\u001B[39;00m\n\u001B[1;32m    966\u001B[0m \n\u001B[1;32m    967\u001B[0m \u001B[38;5;124;03mNote: Unless you set `persistent=True` a GradientTape can only be used to\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1002\u001B[0m \u001B[38;5;124;03m   called with an unknown value.\u001B[39;00m\n\u001B[1;32m   1003\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1004\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tape \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1005\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA non-persistent GradientTape can only be used to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1006\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompute one set of gradients (or jacobians)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1007\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recording:\n\u001B[1;32m   1008\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_persistent:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T11:00:23.634864Z",
     "start_time": "2025-06-14T11:00:23.594681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2)\n",
    "del tape"
   ],
   "id": "48bbd086d23ed433",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m     z \u001B[38;5;241m=\u001B[39m f(w1, w2)\n\u001B[1;32m      3\u001B[0m dz_dw1 \u001B[38;5;241m=\u001B[39m tape\u001B[38;5;241m.\u001B[39mgradient(z, w1)\n\u001B[0;32m----> 4\u001B[0m dz_dw2 \u001B[38;5;241m=\u001B[39m \u001B[43mtape\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradient\u001B[49m\u001B[43m(\u001B[49m\u001B[43mz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m tape\n",
      "File \u001B[0;32m~/Documents/MYSpace/FinPy/.venv/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:1005\u001B[0m, in \u001B[0;36mGradientTape.gradient\u001B[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[1;32m    965\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Computes the gradient using operations recorded in context of this tape.\u001B[39;00m\n\u001B[1;32m    966\u001B[0m \n\u001B[1;32m    967\u001B[0m \u001B[38;5;124;03mNote: Unless you set `persistent=True` a GradientTape can only be used to\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1002\u001B[0m \u001B[38;5;124;03m   called with an unknown value.\u001B[39;00m\n\u001B[1;32m   1003\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1004\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tape \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1005\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA non-persistent GradientTape can only be used to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1006\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompute one set of gradients (or jacobians)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1007\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recording:\n\u001B[1;32m   1008\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_persistent:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T11:03:52.825982Z",
     "start_time": "2025-06-14T11:03:52.819961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2)\n",
    "del tape  # now manual cleanup is required\n"
   ],
   "id": "b7b4bd0a5267a21f",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T01:03:39.343973Z",
     "start_time": "2025-06-11T01:03:39.338772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "\n",
    "    gradients = tape.gradient(z, [c1, c2])"
   ],
   "id": "ffa2b7e7858e3bb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod_: 25502500\n",
      "sum_: 510050\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T11:12:05.241213Z",
     "start_time": "2025-06-14T11:12:05.232294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 **2 + tf.stop_gradient(2 * w1 * w2)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "gradients = tape.gradient(z, w1, w2)\n",
    "\n",
    "x = tf.Variable(1e-50)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = tf.sqrt(x)\n",
    "tape.gradient(z, [x])\n"
   ],
   "id": "55fb3340a07a0c52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=inf>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T11:16:31.223322Z",
     "start_time": "2025-06-14T11:16:31.218967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(1 + tf.exp(-tf.abs(z))) + tf.maximum(0., z)\n",
    "\n",
    "@tf.custom_gradient\n",
    "def my_softplus(z):\n",
    "    def my_softplus_gradients(grads):\n",
    "        return grads * (1 - 1 / (1 + tf.exp(z))) + tf.maximum(0., z )\n",
    "    result = tf.math.log(1 + tf.exp(-tf.abs(z))) + tf.maximum(0., z)\n",
    "    return result, my_softplus_gradients"
   ],
   "id": "8754f4e8b272298a",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T11:52:23.289875Z",
     "start_time": "2025-06-14T11:52:23.283493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "l2_reg = tf.keras.regularizers.l2(0.05)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation = 'relu',\n",
    "                          kernel_initializer = 'he_normal',\n",
    "                          kernel_regularizer = l2_reg),\n",
    "    tf.keras.layers.Dense(1, kernel_regularizer = l2_reg)\n",
    "])\n"
   ],
   "id": "6abd02c5058f5b8",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:06:59.840875Z",
     "start_time": "2025-06-14T12:06:59.837332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]\n"
   ],
   "id": "427299ede34300e8",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:07:01.000708Z",
     "start_time": "2025-06-14T12:07:00.997053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_status_bar(step, total, loss, metrics = None):\n",
    "    metrics = \"-\".join([f\"{m.name}: {m.result():.4f}\" for m in [loss]+ (metrics or [])] )\n",
    "\n",
    "    end = \"\" if step < total else \"\\n\"\n",
    "    print(f\"\\r{step}/{total} -\" + metrics, end = end)"
   ],
   "id": "73b774ee0fc24e2a",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:07:01.464600Z",
     "start_time": "2025-06-14T12:07:01.456690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "mean_loss = tf.keras.metrics.Mean(name = \"mean_loss\")\n",
    "\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError()]"
   ],
   "id": "757c4dfdebe7ffb5",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:14:00.865024Z",
     "start_time": "2025-06-14T12:13:36.883554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"Epoch {epoch} / {n_epochs}\")\n",
    "\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train, y_train)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch, training=True)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            total_loss = tf.add_n([main_loss] + model.losses)\n",
    "\n",
    "        gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        mean_loss.update_state(total_loss)\n",
    "        for metric in metrics:\n",
    "            metric.update_state(y_batch, y_pred)\n",
    "\n",
    "        print_status_bar(step, n_steps, mean_loss, metrics)\n",
    "\n",
    "    # Reset metrics at the end of each epoch\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_state()\n"
   ],
   "id": "b95aaae87917186b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 5\n",
      "412/412 -mean_loss: 0.6340-mean_absolute_error: 0.5106\n",
      "Epoch 2 / 5\n",
      "412/412 -mean_loss: 0.6159-mean_absolute_error: 0.5077\n",
      "Epoch 3 / 5\n",
      "412/412 -mean_loss: 0.6403-mean_absolute_error: 0.5192\n",
      "Epoch 4 / 5\n",
      "412/412 -mean_loss: 0.6362-mean_absolute_error: 0.5176\n",
      "Epoch 5 / 5\n",
      "412/412 -mean_loss: 0.6365-mean_absolute_error: 0.5177\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:15:25.034981Z",
     "start_time": "2025-06-14T12:15:25.031969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for variable in model.variables:\n",
    "    if variable.constraint is not None:\n",
    "        variable.assign(variable.constraint(variable))"
   ],
   "id": "5cc00f5bcf00d329",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:16:45.235845Z",
     "start_time": "2025-06-14T12:16:45.230276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cube(x):\n",
    "    return x**3\n",
    "cube(tf.constant(2.0))"
   ],
   "id": "b677180c3ce41d8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:17:31.595230Z",
     "start_time": "2025-06-14T12:17:31.582703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube(3.)"
   ],
   "id": "72f3cca86fad5f3a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=27.0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:21:07.904781Z",
     "start_time": "2025-06-14T12:21:07.873904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x**3\n",
    "\n",
    "tf_cube(3)\n",
    "\n",
    "tf.cube.python_function(2)"
   ],
   "id": "8f774fb62192fc28",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:30:55.983371Z",
     "start_time": "2025-06-14T12:30:55.946416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@tf.function\n",
    "def loop_demo(x):\n",
    "    result = 0\n",
    "    for i in tf.range(x):\n",
    "        result += i\n",
    "    return result\n",
    "\n",
    "print(tf.autograph.to_code(loop_demo.python_function))\n"
   ],
   "id": "de3f5558101410bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__loop_demo(x):\n",
      "    with ag__.FunctionScope('loop_demo', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        result = 0\n",
      "\n",
      "        def get_state():\n",
      "            return (result,)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal result\n",
      "            (result,) = vars_\n",
      "\n",
      "        def loop_body(itr):\n",
      "            nonlocal result\n",
      "            i = itr\n",
      "            result = ag__.ld(result)\n",
      "            result += i\n",
      "        i = ag__.Undefined('i')\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (ag__.ld(x),), None, fscope), None, loop_body, get_state, set_state, ('result',), {'iterate_names': 'i'})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(result)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:46:21.831903Z",
     "start_time": "2025-06-14T12:46:21.827051Z"
    }
   },
   "cell_type": "code",
   "source": "tf.range(10)",
   "id": "581d1d30eb1bbd0c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:46:43.480724Z",
     "start_time": "2025-06-14T12:46:43.476548Z"
    }
   },
   "cell_type": "code",
   "source": "tf.constant(np.arange(10))",
   "id": "1943ecf8161e372e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:53:49.316683Z",
     "start_time": "2025-06-14T12:53:49.308631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=tf.constant([[1, 2], [3, 4]])\n",
    "w=tf.Variable(tf.random.normal([2, 2]))\n",
    "sparce = tf.sparse.SparseTensor(indices = [[0, 0]], values = [1], dense_shape =[3, 3])\n",
    "ragged = tf.ragged.constant([[1, 2], [3], [4, 5, 6]])\n",
    "ta = tf.TensorArray(dtype = tf.float32, size = 3)\n",
    "ds = tf.data.Dataset.from_tensor_slices(tf.constant([1, 2, 3]))"
   ],
   "id": "e936854f304a4852",
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:53:52.890084Z",
     "start_time": "2025-06-14T12:53:52.885246Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ec99a18a26f8e454",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T05:53:43.981335Z",
     "start_time": "2025-06-16T05:53:43.975128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class CustomLayerNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, epsilon=1e-3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # α (scale) and β (shift): shape = last feature axis\n",
    "        self.alpha = self.add_weight(\n",
    "            name='alpha',\n",
    "            shape=(input_shape[-1],),\n",
    "            dtype=tf.float32,\n",
    "            initializer='ones',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.beta = self.add_weight(\n",
    "            name='beta',\n",
    "            shape=(input_shape[-1],),\n",
    "            dtype=tf.float32,\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Compute mean μ and variance σ² over the last axis (per instance)\n",
    "        mean, variance = tf.nn.moments(inputs, axes=-1, keepdims=True)\n",
    "        std = tf.sqrt(variance + self.epsilon)\n",
    "        normalized = (inputs - mean) / std\n",
    "        return self.alpha * normalized + self.beta\n"
   ],
   "id": "8ecb243460a162b4",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T05:54:23.231187Z",
     "start_time": "2025-06-16T05:54:23.188098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dummy input: batch of 2 samples, 5 features\n",
    "X = tf.random.normal(shape=(2, 5))\n",
    "\n",
    "# Built-in LayerNormalization\n",
    "keras_norm = tf.keras.layers.LayerNormalization(epsilon=1e-3)\n",
    "keras_output = keras_norm(X)\n",
    "\n",
    "# Custom LayerNormalization\n",
    "custom_norm = CustomLayerNormalization(epsilon=1e-3)\n",
    "custom_output = custom_norm(X)\n",
    "\n",
    "# Check difference\n",
    "print(\"Max absolute difference:\", tf.reduce_max(tf.abs(keras_output - custom_output)).numpy())\n"
   ],
   "id": "9213abdca8d8621e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max absolute difference: 1.1920929e-07\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T06:25:06.404456Z",
     "start_time": "2025-06-16T06:25:06.109582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# If using with Dense layers, flatten the images:\n",
    "X_train_flat = X_train.reshape(-1, 28 * 28)\n",
    "X_test_flat = X_test.reshape(-1, 28 * 28)\n",
    "\n",
    "\n"
   ],
   "id": "b08124994bf6689",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7c3331ca6383a418"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
