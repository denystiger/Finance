{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T00:37:52.815269Z",
     "start_time": "2025-07-05T00:37:52.810799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import timeit\n",
    "\n",
    "from jupyter_core.version import parts\n",
    "\n",
    "dict0 = {'a': ['1', '2'], 'b': ['+', '*'], 'c': ['!', '@']}\n",
    " # Unvectorized cart product\n",
    "for a in dict0['a']:\n",
    "    for b in dict0['b']:\n",
    "        for c in dict0['c']:\n",
    "            print({'a': a, 'b': b, 'c': c})\n"
   ],
   "id": "7b2f18d659c5044b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': '1', 'b': '+', 'c': '!'}\n",
      "{'a': '1', 'b': '+', 'c': '@'}\n",
      "{'a': '1', 'b': '*', 'c': '!'}\n",
      "{'a': '1', 'b': '*', 'c': '@'}\n",
      "{'a': '2', 'b': '+', 'c': '!'}\n",
      "{'a': '2', 'b': '+', 'c': '@'}\n",
      "{'a': '2', 'b': '*', 'c': '!'}\n",
      "{'a': '2', 'b': '*', 'c': '@'}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T00:37:53.164662Z",
     "start_time": "2025-07-05T00:37:53.160767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import product\n",
    "# Vectorized Cartegian product\n",
    "dict0 = {\"a\": [\"1\", \"2\"], \"b\": [\"*\", \"+\"], \"c\": [\"!\", \"@\"]}\n",
    "jobs = (dict(zip(dict0, i)) for i in product(*dict0.values()))\n",
    "\n",
    "for i in jobs:\n",
    "    print(i)\n"
   ],
   "id": "138fcc9ecfaf25ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': '1', 'b': '*', 'c': '!'}\n",
      "{'a': '1', 'b': '*', 'c': '@'}\n",
      "{'a': '1', 'b': '+', 'c': '!'}\n",
      "{'a': '1', 'b': '+', 'c': '@'}\n",
      "{'a': '2', 'b': '*', 'c': '!'}\n",
      "{'a': '2', 'b': '*', 'c': '@'}\n",
      "{'a': '2', 'b': '+', 'c': '!'}\n",
      "{'a': '2', 'b': '+', 'c': '@'}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T00:38:18.190421Z",
     "start_time": "2025-07-05T00:37:54.145718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def barrierTouch(sub_r, width=0.5):\n",
    "    t = {}\n",
    "    p = np.log(np.cumprod(1 + sub_r, axis=0))  # cumulative log price\n",
    "\n",
    "    for j in range(p.shape[1]):\n",
    "        for i in range(p.shape[0]):\n",
    "            if abs(p[i, j]) >= width:\n",
    "                t[j] = i\n",
    "                break\n",
    "    return t\n",
    "\n",
    "\n",
    "\n",
    "def main0():\n",
    "    r = np.random.normal(0, 0.01, size=(1000, 10000))\n",
    "    t = barrierTouch(r)\n",
    "    print(f\"{len(t)} paths touched the barrier\")\n",
    "    return t\n",
    "\n",
    "# Run it\n",
    "if __name__ == '__main__':\n",
    "    import timeit\n",
    "    print (min(timeit.Timer('main0()', setup = 'from __main__ import main0').repeat(1, 10)))"
   ],
   "id": "feed08233ae097df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2161 paths touched the barrier\n",
      "2179 paths touched the barrier\n",
      "2210 paths touched the barrier\n",
      "2326 paths touched the barrier\n",
      "2255 paths touched the barrier\n",
      "2246 paths touched the barrier\n",
      "2261 paths touched the barrier\n",
      "2233 paths touched the barrier\n",
      "2257 paths touched the barrier\n",
      "2280 paths touched the barrier\n",
      "24.039596922000783\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T00:38:20.647557Z",
     "start_time": "2025-07-05T00:38:20.645011Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d2f53b26d41798a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T00:38:21.255885Z",
     "start_time": "2025-07-05T00:38:21.252413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def linParts(numAtoms, numThreads):\n",
    "    # partition of atoms with a single loop\n",
    "    parts = np.linspace(0, numAtoms, min(numThreads, numAtoms)+1, dtype=int)\n",
    "    return parts\n"
   ],
   "id": "7fa58b7dbfd7ad02",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def nestedParts(numAtoms, numThreads, upperTriang=False):\n",
    "    # partition of atoms with an inner loop (e.g., quadratic load)\n",
    "    parts = [0]\n",
    "    numThreads_ = min(numThreads, numAtoms)\n",
    "\n",
    "    for num in range(numThreads_):\n",
    "        part = 1 + 4 * (parts[-1]**2 + parts[-1] + numAtoms * (numAtoms + 1.) / numThreads_)\n",
    "        part = (-1 + part**0.5) / 2\n",
    "        parts.append(part)\n",
    "\n",
    "    parts = np.round(parts).astype(int)\n",
    "\n",
    "    if upperTriang:\n",
    "        # Reverse differences to mimic upper triangular load balancing\n",
    "        parts = np.cumsum(np.diff(parts)[::-1])\n",
    "        parts = np.append(np.array([0]), parts)\n",
    "\n",
    "    return parts\n"
   ],
   "id": "228ce418549ff3d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T01:05:35.480376Z",
     "start_time": "2025-07-02T01:05:35.472226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def processJobs(jobs, numThreads=24):\n",
    "    \"\"\"\n",
    "    Process jobs in parallel using multiprocessing.\n",
    "    :param jobs: A list of job dictionaries.\n",
    "    :param numThreads: Number of worker processes.\n",
    "    :return: List of results.\n",
    "    \"\"\"\n",
    "    with mp.Pool(processes=numThreads) as pool:\n",
    "        out = pool.map(worker, jobs)\n",
    "    return out\n",
    "\n",
    "def processJobs_(jobs):\n",
    "    \"\"\"\n",
    "    Process jobs serially (no parallelism).\n",
    "    :param jobs: A list of job dictionaries.\n",
    "    :return: List of results.\n",
    "    \"\"\"\n",
    "    out = [worker(job) for job in jobs]\n",
    "    return out\n",
    "\n",
    "def worker(job):\n",
    "    \"\"\"\n",
    "    Worker function to execute a job.\n",
    "    :param job: A dictionary containing 'func' and its arguments.\n",
    "    :return: Output of the func(**job).\n",
    "    \"\"\"\n",
    "    func = job.pop('func')\n",
    "    return func(**job)\n"
   ],
   "id": "8b1a533eee539276",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T01:05:44.927108Z",
     "start_time": "2025-07-02T01:05:44.920126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def mpPandasObj(func, pdObj, numThreads=24, mpBatches=1, linMols=True, **kargs):\n",
    "    \"\"\"\n",
    "    Parallelize a pandas job over multiple processes.\n",
    "\n",
    "    :param func: Target function to apply; must return a DataFrame or Series.\n",
    "    :param pdObj: Tuple (argName, atoms), where atoms will be partitioned.\n",
    "    :param numThreads: Number of worker processes.\n",
    "    :param mpBatches: Number of jobs per core.\n",
    "    :param linMols: If True, use linear partitioning; else nested.\n",
    "    :param kargs: Additional keyword args for func.\n",
    "    :return: Concatenated result of all parallel jobs.\n",
    "    \"\"\"\n",
    "    # Select partitioning method\n",
    "    atoms = pdObj[1]\n",
    "    argName = pdObj[0]\n",
    "    totalJobs = numThreads * mpBatches\n",
    "    parts = linParts(len(atoms), totalJobs) if linMols else nestedParts(len(atoms), totalJobs)\n",
    "\n",
    "    # Create jobs\n",
    "    jobs = []\n",
    "    for i in range(1, len(parts)):\n",
    "        job = {argName: atoms[parts[i-1]:parts[i]], 'func': func}\n",
    "        job.update(kargs)\n",
    "        jobs.append(job)\n",
    "\n",
    "    # Execute\n",
    "    if numThreads == 1:\n",
    "        out = processJobs_(jobs)\n",
    "    else:\n",
    "        out = processJobs(jobs, numThreads=numThreads)\n",
    "\n",
    "    # Concatenate output\n",
    "    if isinstance(out[0], pd.DataFrame):\n",
    "        result = pd.concat(out)\n",
    "    elif isinstance(out[0], pd.Series):\n",
    "        result = pd.concat(out)\n",
    "    else:\n",
    "        return out  # raw output (e.g. list of scalars)\n",
    "\n",
    "    return result.sort_index()\n"
   ],
   "id": "9bd573a76c98bc00",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T00:48:39.576421Z",
     "start_time": "2025-07-05T00:48:39.574217Z"
    }
   },
   "cell_type": "code",
   "source": "import multiprocessing as mp",
   "id": "5e6417c6a0f08367",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T00:48:33.872436Z",
     "start_time": "2025-07-05T00:48:33.870307Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "47267c4449609cda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T00:49:05.052198Z",
     "start_time": "2025-07-05T00:49:05.045332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "def processJobs(jobs):\n",
    "    # Run jobs sequantially, for debugging\n",
    "    out = []\n",
    "    for job in jobs:\n",
    "        out_ = expandCall(job)\n",
    "        out.append(out)\n",
    "    return out\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "def reportProgress(jobNum, numJobs, time0, task):\n",
    "    #Report progress as asynch jobs are completed\n",
    "    msg = [float (jobNum) / numJobs, (time.time() -time0)/60.]\n",
    "    msg.append(msg[1] *(1/msg[0] - 1))\n",
    "    timeStamp = str(dt.datetime.fromtimestamp(time.time()))\n",
    "    msg = timeStamp+' '+ str(round(mag[0]*100, 2)) + '% ' + task + ' done after ' +\\\n",
    "        str(round(msg[1], 2)) + ' minutes. Remaining ' + str(round(msg[2], 2))+' minutes.'\n",
    "    if jobNum <numJobs: sys.stderr.write(msg+'\\r')\n",
    "    else:sys.stderr.write(mag+'\\n')\n",
    "    return"
   ],
   "id": "dcde9f8847e1d77",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d217f00060ebcdce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
